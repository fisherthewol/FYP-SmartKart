\documentclass[11pt, a4paper, notitlepage]{report}
\usepackage[utf8]{inputenc} % Ensures we can use UTF8.
\usepackage[round,colon]{natbib}
\bibliographystyle{hull}
\usepackage{amsmath}
\usepackage{graphicx}
\graphicspath{ {./images} }
\usepackage{hyperref} % Must come last; allows for links.
\hypersetup{
    hidelinks
}

\title{Smart Kart}
\date{April 2022}
\author{George Jacob Anthony Kokinis}
\begin{document}
\begin{center}
	{\Huge Smart Kart}
	
	\bigskip
	{\Large Final Report}
	
	\bigskip
	Submitted for the BSc in
	
	\bigskip
	{\LARGE Computer Science}
	
	\bigskip
	April 2022
	
	\bigskip
	by 
	
	\bigskip
	{\LARGE George Jacob Anthony Kokinis}
    
    \bigskip
    Word Count: ?? %exclude acknowledgements, abstract, table of contents, references and appendices) of your document.
\end{center}
\newpage
\section{Abstract}
Average speed check zones (ASC zones), typically enforced using SPECS\footnote{SPECS \citep{specsjenop}} in the UK, are being increasingly deployed in throughout the UK; doubling between 2013 and 2016 \citep{BBCSpeedCameraDoubled}. While useful for enforcing speed limits and increasing safety, with \citet{owenAllsop} finding that fatal and serious collisions dropped by 36.4\% at ASC zones installed purposely to reduce collisions, ASC Zones can lead to distracted driving, as the driver has to monitor their speed, which means looking away from the road to their speedometer for brief periods of time.

This project seeks to create a software application for a smartphone, that detects when a vehicle the phone is in enters an ASC zone, starts tracking the vehicle's speed, and gives the driver an audible alert if their average speed is at risk of breaking the speed limit, so as to reduce dependence on the driver to check their speedometer.

\section{Acknowledgements}
I would like to acknowledge the invaluable contributions of Eur Ing Brian Tompsett and Lydia Bryan-Smith (both, at the time of writing, of Hull University) with regards to Latex typesetting; without their guidance I would be stuck with regards to some of its peculiarities.

\tableofcontents

\chapter{Introduction}
\section{Context}\label{sec:Context}
Average speed check zones are an alternative to traditional fixed point speed cameras. Fixed point cameras take two photos a given time-delta apart and measure the car's distance using road markings, to calculate the speed: $ speed = distance \div time $. This is good for enforcing speed in that one position, but does no enforcement for the road before or after the camera. In contrast, ASC zones effectively use the same methodology but across a longer distance (such as half a mile or 1.5 miles between cameras, and a series of cameras across tens of miles); hence effectively enforcing the speed limit across much larger areas of road.

Currently, there are various products for monitoring a driver's speed and for indicating speed cameras; the main smartphone applications in this space are Google Maps \citep{googleMaps} and Waze \citep{waze}; while Apple Maps \citep{appleMaps} will inform you of fixed speed cameras\footnote{In the UK, these were originally "Gatso" cameras, later followed by Truvelo and Truvelo d-cam \citep{dcam}}, it does not inform you of ASC zones.

However, Google Maps does not register ASCs as actual "zones", but instead as a fixed speed camera at the start of the zone. Waze displays your progression through an ASC, but does not calculate your average speed. TomTom GO Navigation \citep{tomtomGo} does track your average speed in an ASC zone, but operates on a paid subscription model, so is not available to everyone. Hence, there is space in the market for a free solution to monitoring speed in ASC zones.
\section{The Problem}
While lawful drivers should be aware of their speed anyway, it is likely that many check their speed more often and with more discretion whilst within an ASC zone. This means they may be focused on their speedometer when something important is passed, such as a direction sign, a signal from another road user, or an overhead gantry message - such as the "Red X" on Smart Motorways\footnote{Smart Motorways \citep{SmartMotorways}}, or a speed limit change. 
\section{A solution}
By creating a smartphone application that warns a user if they are about to 
exceed the speed limit, the load on the driver can be reduced, allowing them to 
have more awareness of the road. By making this application free to use 
(whether free or supported by advertisements), this increases availability, 
potentially increasing the impact of this project.
\section{Report Structure}
The rest of this report is structured into the following chapters:
\begin{itemize}
	\item Background: Describing and laying out technologies and concepts that may be used in the development of the application or are useful for understanding other technologies.
	\item Aims and Objectives: Specification in detail about what features the application should have and how this will be tested or measured.
	\item Design: A description of the initial design, visual and technical, for the application, and design(s) for surveys to gain feedback on the UI of the application.
	\item Technical Development: Discussion around the development of the application. Note that the actual development log will be listed in Appendix \ref{app:GitLog}.
    \item Evaluation: Discussion and Evaluation of how closely the application meets the Aims and Objectives in the aforementioned chapter.
\end{itemize}
After which there will be Appendices and the Bibliography. % Remove this?
\chapter{Background}
The development of this project requires understanding and examination of various topics across various fields; including Kinematics, Programming, Law, and UX. Hence this chapter discusses and describes relevant topics.
\section{Speed Cameras}
\subsection{Fixed-Point Cameras}
In the United Kingdom, traditional fixed-point speed cameras were of a "Gatso" type, later replaced by "Truvelo", and later Truvelo D-Cam. They are installed either by the Local Authority, the local Police Force, or the relevant highways agency\footnote{\textit{National Highways} in England, \textit{Transport Scotland} in Scotland, \textit{Traffic Wales} in Wales, and \textit{DfI Roads} in Northern Ireland.}; with all three often forming "Road Safety Partnerships" for given areas, that can then receive grants from the central government \citep{RSPGrantDetails} to use for, among other things, the installation of speed cameras. The decision of where to install a speed camera is made on a few factors; with \citet{SpeedCameraInstalltion} claiming that at the proposed location, greater than 20\% of drivers must exceed the speed limit, and that there must be a history of serious accidents.

At first glance, fixed-point cameras appear to work on a rather simple principle. As described in the \nameref{sec:Context}, the simplest view of how to obtain the speed of a vehicle is $ speed = \frac{distance}{time} $. Hence the camera can take two measurements a known time apart, work out the distance the vehicle travels between those measurements, and calculate the speed. 
Fixed-point cameras use K and Ku-band Radar signals to determine the speed of the vehicle; K-band meaning that the frequency used is between 18 and 27 GHz \citep{IEEERadar}; and Radar, an acronym for Radio Detection and Ranging \citep{RadarNaming}, referring to the usage of a transmitter, receiver, and processing of K-Band or adjacent frequencies (in the Radio or Microwave ranges) to determine properties of an object. The time of flight is the total time between transmitting a signal and receiving the reflection; and this can be used to determine the distance. The speed of light is known\footnote{299 792 458 metres per second in a vacuum, known as \textit{c}, and slower in air: which can be calculated with $ speed = c \div n $ \citep{HechtOptics}; where n is the refractive index of the medium. \citet{refIndxAir} gives 1.0003 as the approximate refractive index of light in air; approximate as it can be affected by factors such as moisture content.}, and so the distance can be calculated using a rearrangement of the previous formula: $ distance = speed  \cdot time $. Hence, overall, the speed of a vehicle travelling towards/away from the camera can be calculated by:
\begin{equation}
	c' = \frac{c}{1.003}
\end{equation}
\begin{equation}
	first~measurement = c' \cdot time~of~flight
\end{equation}
\begin{equation}
	second~measurement = c' \cdot time~of~flight
\end{equation}
\begin{equation}
	speed = \frac{\left|second~measurement~-~first~measurement\right|}{time~between~measurements}
\end{equation}

However, this requires storage and memory of two time of flight measurements, and two distance measurements. Instead, an inherent property of waves can be used to determine the speed. The Doppler effect, first described by \citet{dopplerGerman} but better described for Radar applications by \citet{dopplerWolff}, is the property of waves that, as an emitter moves away or towards a stationary receiver (or vice versa), there is an apparent change in the frequency. The frequency is higher if the motion is towards the stationary point, as the receiver will receive a greater number of waves per second; and lower frequency if motion is away from the stationary point as it receives less waves per second. Due to this, the "doppler shift" - the difference between real and effective frequency, $ \Delta f $ - can be calculated as follows:
\begin{equation}
	\Delta v = -(v_{receiver} - v_{source})
\end{equation}
\begin{equation}
	\Delta f = \frac{\Delta v}{c'} \cdot f_{emitted}
\end{equation}
In the case of the speed camera, we can control $ f_{emitted} $, and we must take into account the fact that doppler shift will occur twice. Hence, the velocity $ v $ of a car can be calculated as such:
\begin{equation}\label{eq:DopplerSpeed}
	v = \frac{\Delta f}{f_{emitted}} \cdot \frac{c'}{2}
\end{equation}

If the vehicle's velocity calculated by equation \ref{eq:DopplerSpeed} exceeds the road's speed limit, the camera takes two photos in quick succession. In the original Gatso cameras these photos were on photographic film, which would be collected and processed by the local police force on a regular basis. Retrofitted Gatso and the newer Truvelo \& DCam systems upload their photographs and Radar Measurements to a system with the local Police Force; these systems are believed to be connected with the Police National Computer (PNC) \citep{PNC}. These photos contain the registration plate of the vehicle\footnote{Gatso cameras must take a photo of the rear of the vehicle due to the use of a bright flash, so will always obtain the registration plate; but do not photograph the driver and so the identity of the offender can be disputed. Truvelo \& DCam may take photos of the front, thereby identifying the offender, but some vehicles lack front plates.}, and markings on the road. These markings are graduated and are used to determine the distance the vehicle travels between the photos, and hence a speed can be determined; this \textit{secondary measurement} is used by prosecution teams to confirm an offence was made, but is not absolutely needed for a prosecution.

\subsection{Average Speed Cameras}
It may be wise to think, since average speed cameras were introduced after fixed-point cameras, that they would be significantly more advanced. In some ways they are, but in other ways they are much simpler.

\citet{ANPRNPCC} tells us that ANPR, Automatic Number Plate Recognition, refers to the reading of vehicle number-plates using OCR\footnote{Optical Character Recognition \citep{OCR}.}, storing information about those number-plates (such as the location and time of the scan), and querying a central system (such as the PNC) for details about the vehicle and its registered keeper. Number plates in the UK and generally in the EU are retroreflective; meaning that light is reflected back in direction it came from. Hence, most ANPR systems, including those used by Average Speed Cameras, take photos and use a flash in the infrared range to take a clearer image of a number plate.

Average Speed Cameras are deployed as systems consisting of multiple ANPR-equipped cameras, at known intervals, along a road or roads. These cameras can be permanently installed along roads, or temporarily installed at the site of roadworks. Installations come in various forms; they are installed on their own poles, on existing street furniture (EG lampposts), and on overhead gantries. The system has knowledge of the road distance (as opposed to direct distance, colloquially "as the crow flies") between cameras, and uses this knowledge combined with timestamped photographs of vehicles passing the cameras (with ANPR being used to match number-plates to timestamps) to calculate an average speed. This average takes into account factors such as changing lanes, and using junctions in an attempt to defeat the system.

A given system must have at least two cameras (so there are two measurements to calculate speed from), but there is no legal or algorithmic upper bound on the number of cameras in, or the length of, a single system \citep{cbASC}. Any upper bound is likely to be budgetary, technological, or jurisdictional; that is, the authority responsible for the system cannot afford the number of cameras, the computers to store and process data from the cameras, or legally cannot deploy cameras past a county or city boundary.

Put simply, average speed cameras go back to using the simple equation of $ speed = \frac{distance}{time} $. By applying this over a larger distance of road, rather than a small section, it encourages drivers to stay at or below the speed limit, and to drive in a smoother manner.

\subsection{Summary}
With regards to the application this project produces, from the previous knowledge, the following factors should be noted:
\begin{itemize}
    \item Fixed-point cameras are not relevant to average speed cameras in terms of applied technology, and therefore aren't relevant to the application. At most, there may be scope to provide notice of fixed cameras within the app.
    \item There is no public knowledge of pairing between any two cameras in a system; they may be paired sequentially or randomly.
    \item Hence, if a dataset has specific locations of cameras within a system, it is reasonable that average speed should be calculated between sequential cameras - IE between the current position and the previous camera, then reset at the next camera.
    \item If the dataset does not have specific locations, and only the start and end, then the average speed should be calculated between the start and end.
\end{itemize}

\section{Predicting Speed}
The change in speed over time, acceleration, is
\begin{equation}\label{eq:Accel}
    a = \frac{v - u}{t}
\end{equation}
This allows for finding change of speed in the past; but the application must effectively forecast if a user's vehicle is going to exceed the speed limit. \citet{accelerationForecasting} provides and validates a model to predict maximum acceleration for trucks (LGVs). However it does not suggest whether their model works for smaller vehicles, and the model requires input parameters of tractive effort calculated from transmission efficiency, current speed, engine power, etcetera; it's a very comprehensive model, but an average driver isn't going to want to go and find these details for their vehicle just to track average speed. Hence this model is unsuitable for the application; however the methodology may be useful to analyse.  

Instead of a complex model, the application can just use past acceleration to predict future speed. This is naive model, but by using appropriate development techniques such as separation of concerns, this model can be changed for a more accurate one in the future. The basis, then, is a simple rearrangement of \ref{eq:Accel}:
\begin{equation}
    v = u + a \cdot t
\end{equation}
The main tuning parameter of this model for forecasting is t, time; whether this is user configurable (a setting saying "Notify me t seconds before exceeding the limit") or "hardcoded" is a consideration to be made. As well, this needs to be used with some hysteresis; it will be exceedingly annoying to the user if the application constantly alternates the alerting state.

\section{Programming and Development}
There are various options for platforms on which this application could be developed. This section discusses options, and ultimately decides as to which platform should be used.

\subsection{Cross-platform frameworks}
One contemporary paradigm is the use of cross-platform frameworks; where a developer writes their code using provided libraries, and the framework handles the "mapping" between calls into the libraries and the various host features. These frameworks can range from intrinsic to the language - in the case of Java and the openJDK \citep{openJdk}, where a JVM is almost completely necessary for running the program and so is provided by the Java developers - to external frameworks developed by entities separate to those who develop the language.

\paragraph{Flutter}
Flutter \citep{FlutterWebsite} is a cross-platform framework provided by Google (but is open source, so can be modified by the general public) that allows developers to build "multi-platform applications from a single codebase". It uses and itself is written in Dart, Google's "client optimized language for fast apps on any platform" \citep{dartWebsite}. Bar the singular codebase, it provides explicit widgets for specific platform actions, such as permissions dialogs.

Being provided by Google and using a language from Google means there is a high level of integration between langauge features and the framework, whilst still maintaining separate development groups.

\paragraph{UNO Platform}
UNO Platform is a framework for "Pixel-Perfect Multi-Platform Applications with C\# and WinUI" \citep{UnoWebsite}. It allows a developer to write once and compile applications for most major platforms, whilst also allowing for platform-specific code. 

The use of C\# and WinUI is advantageous, as the University of Hull teaches C\# throughout undergraduate Computer Science courses, so prior knowledge can be reused; and WinUI knowledge can be reused in future applications.

\paragraph{MAUI}
.NET MAUI is a cross-platform UI framework that allows .NET developers to write UIs that work on multiple .NET targets \citep{MAUIWebsite}. All .NET targets on .NET 6 share the same "base class library", meaning the underlying hardware and platform is abstracted away, but UI definition is still platform specific. MAUI allows a developer to use XAML to define UIs that work across Android, iOS, macOS, and Windows.

Again, the use of .NET (and therefore most likely C\#) is advantageous for building on prior knowledge. However, being a framework still in "preview", whilst meaning there's still improvements to be made and inherent longevity, means that MAUI may be more prone to bugs and errors than a more mature framework.

\paragraph{Summary}
Whilst these frameworks all ease cross-platform development, and help developers use a single codebase instead of multiple, for this project expediency and ease of development means that cross-platform is less important than a working application in the first place. For example, all of these frameworks enable the application to run on a desktop or laptop computer; but the chances of a user bringing even a laptop into their vehicle is very low, and the objective of this project is a smartphone application. So the potential added complexity of using a multi-platform framework to enable use on a platform that isn't relevant is not conducive to the project.

Hence, this project will not use a multi-platform framework, and will instead use platform-native development on a mobile platform.

\subsection{Platform Native}
\citet{MobileMarketShare} gives Android and iOS an approximate combined market share of 99.27\% as of March 2022. However, even in the remaining 0.73\% of the market, there are various options; Tizen\footnote{Backed by the Linux Foundation, but primarily developed by Samsung.}, KaiOS, and SailfishOS to name a few, as well as mobile versions of desktop systems, such as pureOS.

While all could be good platforms for this project, Android and iOS' combined dominance and availability make them the two platforms to decide between, if this application is to provide the largest benefit to the public. Hence it is prudent to contrast and compare these platforms, and discount the others.

\paragraph{Android} Android is a platform originally developed by the Android Open Source Project, but later adopted and marketed by Google. The platform is based around the JVM, originally Dalvik (which JIT'd\footnote{JIT: Just-in-Time, a methodology in which code is compiled to an intermediate form, then during runtime interpreted into machine instructions; See \citet{JITHistory}.} all applications) but later ART (in which applications are compiled to native code during installation), and hence originally development was done in Java.

However, since 2017 Kotlin has had "first-class support" from the Android Team \citep{KotlinPreferred}, and since 2019 has been the preferred language for android development \citep{KotlinFirst}. Kotlin is a language from JetBrains\texttrademark\, with modern functional and object-oriented features; originally on the JVM, but since Kotlin 1.3, a beta feature to compile directly to native executables has been available. When originally announced, \citet{KotlinAnnounced} described Kotlin as has having "features so desperately wanted by the developers".

\paragraph{iOS} iOS is the platform used by Apple on their iPhones and the majority of their iPads (until the introduction of iPadOS). Apple provides an iOS development kit, iOS SDK, and an IDE, XCode, as well as documentation and other tooling.

Historically iOS applications were written in Objective-C, an object-oriented language originally developed in the 1980s. However since reaching version 1.0 in 2014, Swift \citep{Swift1.0} has transitioned into being the main language for iOS development. Swift is also an object-oriented language.

\paragraph{Summary} Both Android and iOS have mature and full-featured SDKs, tools, and ecosystems. Both have historical and current languages, with iOS' languages integrating more tightly with the SDK than Android's.

However, the advantage Android holds over iOS is one of cost. To develop for iOS native, a developer is required to have a MacOSX device to run XCode and the rest of the toolkit; even when using cross-platform frameworks, this requirement remains. At the time of writing the cheapest MacOSX system from Apple UK is £699 for a base Mac mini; and that price doesn't include a screen or any peripherals. £699 is a significant outlay for a singular developer.

In comparison, Android Studio\footnote{The primary IDE for Android development, \citep{androidstudio}} is OS agnostic; it will run on Windows, Mac, Linux, and even some ChromeBooks, as long as they have a 64-bit processor, and enough RAM and Storage. It is also possible to develop an Android app without Android Studio; the build system, gradle, is usable from the command line, so any text editor could be used for development.

Furthermore, publishing an application is another advantage for Android. To publish an iOS app, a developer must enrol in the Apple Developer Program and pay an annual fee of \$99 for individuals or \$299 for companies \citep{AppleDevProgram}; this is regardless of whether your application is free or not. Other than this, there is no supported way of publishing applications.

On Android, a developer can publish their application to the Google Play Store \citep{googlePlay}, to alternative marketplaces, or just offer application files (specifically APKs) for download.
\begin{itemize}
	\item To publish on Google Play, a developer must pay a one-off fee of \$25; bar this, any costs are as proportions of advert revenue and of transactions users make when buying an application or making in-app purchases; so a completely free app is free to publish.
	\item Alternative markets include F-Droid \citep{FDroid}, which is completely free to publish to, but doesn't allow your application to cost money; it does allow for you to ask for donations, or have some in-app purchases.
	\item Finally, although disabled by default, Android allows for installing applications from downloaded files, also known as sideloading \citep{sideloading}. A developer could develop and compile their application, then distribute the resulting apk file through any method they like - whether a download link on a website, or with some form of repository.
\end{itemize}

Hence, this project will develop an application for Android native; as it provides the most broad and easily accessible platform to develop and publish on. Furthermore, this project will use Kotlin as the language for development, as this is the contemporary choice; with \citet{KotlinFirst} quoting Google as saying "If you’re starting a new project, you should write it in Kotlin".

\chapter{Aims and Objectives}
Fill later.
\chapter{Design}
Once an initial design is proposed, any changes to that design should be noted and tested to ensure there are no regressions. In this section, initial designs for the UI, the user flows, and application structures are proposed.
\section{User Flows}
The basic flow of application is laid out in figure \ref{fig:BasFlow}. The rest of the flows are effectively automation around this basic flow.
\begin{figure}
    \centering
    \caption{Basic flow for the application.}
    \label{fig:BasFlow}
    \scalebox{0.5}{\includegraphics{UserStartedFlow.png}}
\end{figure}

The main automation is effectively a separate loop that invokes the original flow, by checking for location of the user and comparing to a dataset of average speed zones; and similarly the original flow must now return to the invocation loop when it determines it has exited a zone. This is displayed in figure \ref{fig:AutoFlow}.
\begin{figure}
    \centering
    \caption{Flow with automation.}
    \label{fig:AutoFlow}
    \scalebox{0.5}{\includegraphics{AutomatedFlow.png}}
\end{figure}

\chapter{Technical Development}
While the actual development of code can be found in appendix \ref{app:GitLog}, it is worthwhile discussing, separately to that, justification and reasoning behind certain decisions and implementations, as well as more general discussion about development on Android.

\section{Settings Page}
Certain parameters of the application are user configurable; for example, except for in Automatic mode, the speed limit can be changed by the user, and the forecast time for the model can be configured by the user. However, the speed limit should be changeable from the main interface of the application, while the forecast time does not need to be. Hence a "settings page" should be created.

\citet{settingsAndroid} provides a guide on how to implement a settings screen, using a \textit{PreferenceScreen} fragment. By using this part of the Android Jetpack library, a developer doesn't have to implement their own Settings system. However, to get to this settings page, the user must interact with something; one idea is for a settings button on the top bar of the application, which on Android is referred to as the "ActionBar". \citet{toolbarAndroid} provides information on how to configure an ActionBar that works across past and future android versions, and allows for action buttons. However, despite implementing this in the project, a settings button was never seen on the action bar throughout development. A future task for this project would be revisit and attempt to implement this; it is more likely to be a bug with the project's code than with the underlying Android libraries.

For testing purposes, a button to reach the settings page was explicitly added. It was removed during design of the rest of the UI, then re-added at the end. The settings page itself can be found in figure \ref{fig:settingsPage}; currently containing just two settings, but could easily be extended for further features.

\begin{figure}
	\centering
	\caption{Settings page at end of main development.}
	\label{fig:settingsPage}
	\scalebox{0.2}{\includegraphics{SettingsPage.png}}
\end{figure}
\pagebreak

\section{Android Resources}
Android resources are "additional files and static content that your code uses" \citep{resourcesAndroid}, including images, sounds, layouts, and (static) values. In this section the use and features of some resource forms is discussed.

Resources can be "qualified" with a number of factors, such as device orientation, type, "night mode", language, etc.

\subsection{Drawables}
Images in Android are considered to be "Drawables", and they can be either raw images in Bitmap or Vector form, or more Complex forms. For example, you can define a StateList composed of other drawables, and change between them from within your code.

This project's only explicit use of a drawable is as a background SVG\footnote{Scalable Vector Graphics \citep{SVGW3C}} used to display the speed limit, imitating the background of a UK Speed Limit sign. However, this could become part of a StateList, with other countries backgrounds, or signs with specific meaning (E.G. the UK's National Speed Limit sign), to better improve a user's recognition of the speed limit.

The use of an SVG instead of a bitmap allows for better scaling for different UI sizes; bitmap (also known as raster) graphics are prone to artifacts on upscaling (as information has to be interpolated).

\subsection{Layouts}
When defining an activity's or fragment's initial state, a developer should provide a layout file that defines the initial state in XML. It is theoretically possible to build a layout in code, and it is sometimes necessary to make changes in code; when \textit{inflating} its layout, an Activity needs to add a fragment to take the place of a \textit{FragmentContainerView}. However the actual layout should be in the layout resource file, and the code should manipulate the data displayed within the layout.

Manipulating views within a layout has historically been a case of calling \textit{findViewById()} to get the view to manipulate. However this is not type safe and has few compile-time guarantees. Since Android Studio 3.6 (and the version of Jetpack released alongside it), this can be replaced by View Binding \citep{viewBindingAndroid}; upon creation of an activity or fragment, it inflates its layout and stores the root element as a member field. Then, instead of calling findViewById(), a developer can access binding.viewId.property, which provides nullability and type-safety.

\subsection{Strings}
Android allows for easy localisation through the use of string resources. When the developer uses some text, the code refers to the string resource instead; based on the device's locale, this is substituted for a translated string if available.

This extraction of string resources also allows for a "single source of truth"; rather than having to find all instances of a string in code and replace them, a developer wishing to change text just has one location to alter.

\appendix
\chapter{Development Log}\label{app:GitLog}
TestTestTest

\bibliography{finalrep}
\end{document}